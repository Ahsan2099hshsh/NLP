{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0022b12-4453-4e9f-9503-60efd0404ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Texts:\n",
      "['love artificial intelligence', 'ai changing world rapidly', 'nlp course amazing helpful']\n",
      "\n",
      "Vocabulary / Features:\n",
      "['ai' 'amazing' 'artificial' 'changing' 'course' 'helpful' 'intelligence'\n",
      " 'love' 'nlp' 'rapidly' 'world']\n",
      "\n",
      "TF-IDF Matrix (rows = documents, columns = words):\n",
      "[[0.         0.         0.57735027 0.         0.         0.\n",
      "  0.57735027 0.57735027 0.         0.         0.        ]\n",
      " [0.5        0.         0.         0.5        0.         0.\n",
      "  0.         0.         0.         0.5        0.5       ]\n",
      " [0.         0.5        0.         0.         0.5        0.5\n",
      "  0.         0.         0.5        0.         0.        ]]\n",
      "\n",
      "IDF Values:\n",
      "{'ai': np.float64(1.6931471805599454), 'amazing': np.float64(1.6931471805599454), 'artificial': np.float64(1.6931471805599454), 'changing': np.float64(1.6931471805599454), 'course': np.float64(1.6931471805599454), 'helpful': np.float64(1.6931471805599454), 'intelligence': np.float64(1.6931471805599454), 'love': np.float64(1.6931471805599454), 'nlp': np.float64(1.6931471805599454), 'rapidly': np.float64(1.6931471805599454), 'world': np.float64(1.6931471805599454)}\n"
     ]
    }
   ],
   "source": [
    "# -------- TEXT PREPROCESSING + TF-IDF ---------\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# download only first time\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "texts = [\n",
    "    \"I love Artificial Intelligence!\",\n",
    "    \"AI is changing the world rapidly.\",\n",
    "    \"This NLP course is amazing and very helpful.\"\n",
    "]\n",
    "\n",
    "# ---------- Cleaning + Preprocessing ----------\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()                              # lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)             # remove punctuation/numbers\n",
    "    tokens = nltk.word_tokenize(text)                # tokenization\n",
    "    tokens = [w for w in tokens if w not in stop_words]  # remove stopwords\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]   # lemmatization\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "clean_texts = [preprocess(t) for t in texts]\n",
    "print(\"Cleaned Texts:\")\n",
    "print(clean_texts)\n",
    "\n",
    "# ---------- TF-IDF ----------\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(clean_texts)\n",
    "\n",
    "print(\"\\nVocabulary / Features:\")\n",
    "print(tfidf.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTF-IDF Matrix (rows = documents, columns = words):\")\n",
    "print(X.toarray())\n",
    "\n",
    "print(\"\\nIDF Values:\")\n",
    "idf_values = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))\n",
    "print(idf_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb55d193-5fac-4932-85de-5290ff6b4104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary / Features:\n",
      "['ai' 'amazing' 'and' 'artificial' 'changing' 'course' 'helpful'\n",
      " 'intelligence' 'is' 'love' 'nlp' 'rapidly' 'the' 'this' 'very' 'world']\n",
      "\n",
      "Bag of Words Matrix:\n",
      "[[0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1]\n",
      " [0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts = [\n",
    "    \"I love Artificial Intelligence\",\n",
    "    \"AI is changing the world rapidly\",\n",
    "    \"This NLP course is amazing and very helpful\"\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "print(\"Vocabulary / Features:\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nBag of Words Matrix:\")\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488db6b-16c9-46f9-9848-fae94f4a8e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
